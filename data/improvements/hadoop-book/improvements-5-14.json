{
    "Method_Improvements": {
        "Improvements": [
            {
                "Improvement": "Use enhanced for loop instead of traditional for loop",
                "Change_Diff": "- for (int i=0; i < args.length; ++i) { if... } \n+ for (String arg : args) { if... }",
                "Description": "Instead of using a traditional for loop to iterate over `args`, use an enhanced for loop. This is more readable and eliminates the use of an index variable.",
                "Start": 18,
                "End": 46
            },
            {
                "Improvement": "Remove redundant initialization",
                "Change_Diff": "- int num_maps=cluster.getTaskTrackers() * jobConf.getInt(\"test.sort.maps_per_host\",10);\n- int num_reduces=(int)(cluster.getMaxReduceTasks() * 0.9);\n+ int num_maps;\n+ int num_reduces;",
                "Description": "The variables `num_maps` and `num_reduces` are initialized twice in a row, which is unnecessary. Remove the initial assignment and leave only the ones where they receive actual values based on the job configuration.",
                "Start": 7,
                "End": 11
            },
            {
                "Improvement": "Use try-with-resources",
                "Change_Diff": "- JobClient client=new JobClient(jobConf);\n+ try (JobClient client = new JobClient(jobConf)) { ... }",
                "Description": "In order to handle resources such as `JobClient` in an efficient way, it's recommended to use the try-with-resources statement, which ensures that each resource is closed at the end of the statement.",
                "Start": 6,
                "End": 65
            }
        ],
        "Final code": "public int run(String[] args) throws Exception {\n  JobConf jobConf=new JobConf(getConf(),Sort.class);\n  jobConf.setJobName(\"join\");\n  jobConf.setMapperClass(IdentityMapper.class);\n  jobConf.setReducerClass(IdentityReducer.class);\n  try (JobClient client=new JobClient(jobConf)) {\n    ClusterStatus cluster=client.getClusterStatus();\n    int num_maps;\n    int num_reduces;\n    ...\n    for (String arg : args) {\n        if (\"-m\".equals(arg)) {\n            num_maps=Integer.parseInt(arg);\n        } else if (\"-r\".equals(arg)) {\n            num_reduces=Integer.parseInt(arg);\n        } \n        ...\n    }\n    ...\n  }\n}"
    },
    "Old_Method": "/** \n * The main driver for sort program. Invoke this method to submit the map/reduce job.\n * @throws IOException When there is communication problems with the jobtracker.\n */\n@Override public int run(String[] args) throws Exception {\n  JobConf jobConf=new JobConf(getConf(),Sort.class);\n  jobConf.setJobName(\"join\");\n  jobConf.setMapperClass(IdentityMapper.class);\n  jobConf.setReducerClass(IdentityReducer.class);\n  JobClient client=new JobClient(jobConf);\n  ClusterStatus cluster=client.getClusterStatus();\n  int num_maps=cluster.getTaskTrackers() * jobConf.getInt(\"test.sort.maps_per_host\",10);\n  int num_reduces=(int)(cluster.getMaxReduceTasks() * 0.9);\n  String sort_reduces=jobConf.get(\"test.sort.reduces_per_host\");\n  if (sort_reduces != null) {\n    num_reduces=cluster.getTaskTrackers() * Integer.parseInt(sort_reduces);\n  }\n  Class<? extends InputFormat> inputFormatClass=SequenceFileInputFormat.class;\n  Class<? extends OutputFormat> outputFormatClass=SequenceFileOutputFormat.class;\n  Class<? extends WritableComparable> outputKeyClass=BytesWritable.class;\n  Class<? extends Writable> outputValueClass=TupleWritable.class;\n  String op=\"inner\";\n  List<String> otherArgs=new ArrayList<String>();\n  for (int i=0; i < args.length; ++i) {\n    try {\n      if (\"-m\".equals(args[i])) {\n        num_maps=Integer.parseInt(args[++i]);\n      }\n else       if (\"-r\".equals(args[i])) {\n        num_reduces=Integer.parseInt(args[++i]);\n      }\n else       if (\"-inFormat\".equals(args[i])) {\n        inputFormatClass=Class.forName(args[++i]).asSubclass(InputFormat.class);\n      }\n else       if (\"-outFormat\".equals(args[i])) {\n        outputFormatClass=Class.forName(args[++i]).asSubclass(OutputFormat.class);\n      }\n else       if (\"-outKey\".equals(args[i])) {\n        outputKeyClass=Class.forName(args[++i]).asSubclass(WritableComparable.class);\n      }\n else       if (\"-outValue\".equals(args[i])) {\n        outputValueClass=Class.forName(args[++i]).asSubclass(Writable.class);\n      }\n else       if (\"-joinOp\".equals(args[i])) {\n        op=args[++i];\n      }\n else {\n        otherArgs.add(args[i]);\n      }\n    }\n catch (    NumberFormatException except) {\n      System.out.println(\"ERROR: Integer expected instead of \" + args[i]);\n      return printUsage();\n    }\ncatch (    ArrayIndexOutOfBoundsException except) {\n      System.out.println(\"ERROR: Required parameter missing from \" + args[i - 1]);\n      return printUsage();\n    }\n  }\n  jobConf.setNumMapTasks(num_maps);\n  jobConf.setNumReduceTasks(num_reduces);\n  if (otherArgs.size() < 2) {\n    System.out.println(\"ERROR: Wrong number of parameters: \");\n    return printUsage();\n  }\n  FileOutputFormat.setOutputPath(jobConf,new Path(otherArgs.remove(otherArgs.size() - 1)));\n  List<Path> plist=new ArrayList<Path>(otherArgs.size());\n  for (  String s : otherArgs) {\n    plist.add(new Path(s));\n  }\n  jobConf.setInputFormat(CompositeInputFormat.class);\n  jobConf.set(\"mapred.join.expr\",CompositeInputFormat.compose(op,inputFormatClass,plist.toArray(new Path[0])));\n  jobConf.setOutputFormat(outputFormatClass);\n  jobConf.setOutputKeyClass(outputKeyClass);\n  jobConf.setOutputValueClass(outputValueClass);\n  Date startTime=new Date();\n  System.out.println(\"Job started: \" + startTime);\n  JobClient.runJob(jobConf);\n  Date end_time=new Date();\n  System.out.println(\"Job ended: \" + end_time);\n  System.out.println(\"The job took \" + (end_time.getTime() - startTime.getTime()) / 1000 + \" seconds.\");\n  return 0;\n}\n",
    "File_Path": "hadoop-book/src/main/java/com/hadoopilluminated/examples/Join.java",
    "Start": 2701,
    "Stop": 7066,
    "Project_Name": "data/projects/hadoop-book",
    "Method_Name": "run"
}