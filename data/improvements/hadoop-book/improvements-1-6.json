{
    "Method_Improvements": {
        "Improvements": [
            {
                "Improvement": "Use of try-with-resources for AutoCloseable resources",
                "Change_Diff": "- JobClient client=new JobClient(job);\n+ try (JobClient client = new JobClient(job)) {",
                "Description": "The `JobClient` class implements `AutoCloseable`, thus, it should be used in a try-with-resources block to ensure that it is closed properly and to avoid potential resource leaks.",
                "Start": 15,
                "End": 16
            },
            {
                "Improvement": "Exception handling and logging",
                "Change_Diff": "- System.out.println(\"ERROR: Required parameter missing from \" + args[i - 1]);\n+ LOG.error(\"ERROR: Required parameter missing from \" + args[i - 1], except);",
                "Description": "When an exception is caught, the stack trace should be logged, not only a simple message. This can be helpful in diagnosing the root cause of the problem. Use a logging framework such as SLF4J or Logback instead of using `System.out.println` and `System.err.println` for better logging management.",
                "Start": 39,
                "End": 42
            },
            {
                "Improvement": "Use constants for repeated String literals",
                "Change_Diff": "- job.getInt(\"test.randomtextwrite.maps_per_host\",10);\n+ job.getInt(MAPS_PER_HOST,10);",
                "Description": "There are several repeated String literals in the code. These should be replaced with constant variables to reduce the likelihood of typos and to make it easier to change the value in the future.",
                "Start": 16,
                "End": 29
            }
        ],
        "Final code": "public int run(String[] args) throws Exception {\n  if (args.length == 0) {\n    return printUsage();\n  }\n  JobConf job=new JobConf(getConf());\n  job.setJarByClass(RandomTextWriter.class);\n  job.setJobName(\"random-text-writer\");\n  job.setOutputKeyClass(Text.class);\n  job.setOutputValueClass(Text.class);\n  job.setInputFormat(RandomWriter.RandomInputFormat.class);\n  job.setMapperClass(Map.class);\n  try (JobClient client = new JobClient(job)) {\n    ClusterStatus cluster=client.getClusterStatus();\n    int numMapsPerHost=job.getInt(MAPS_PER_HOST,10);\n    long numBytesToWritePerMap=job.getLong(BYTES_PER_MAP,1 * 1024 * 1024* 1024);\n    if (numBytesToWritePerMap == 0) {\n      LOG.error(\"Cannot have test.randomtextwrite.bytes_per_map set to 0\");\n      return -2;\n    }\n    long totalBytesToWrite=job.getLong(TOTAL_BYTES,numMapsPerHost * numBytesToWritePerMap * cluster.getTaskTrackers());\n    int numMaps=(int)(totalBytesToWrite / numBytesToWritePerMap);\n    if (numMaps == 0 && totalBytesToWrite > 0) {\n      numMaps=1;\n      job.setLong(BYTES_PER_MAP,totalBytesToWrite);\n    }\n    Class<? extends OutputFormat> outputFormatClass=SequenceFileOutputFormat.class;\n    List<String> otherArgs=new ArrayList<String>();\n    for (int i=0; i < args.length; ++i) {\n      try {\n        if (\"-outFormat\".equals(args[i])) {\n          outputFormatClass=Class.forName(args[++i]).asSubclass(OutputFormat.class);\n        }\n else {\n          otherArgs.add(args[i]);\n        }\n      }\n catch (ArrayIndexOutOfBoundsException except) {\n        LOG.error(\"ERROR: Required parameter missing from \" + args[i - 1], except);\n        return printUsage();\n      }\n    }\n    job.setOutputFormat(outputFormatClass);\n    FileOutputFormat.setOutputPath(job,new Path(otherArgs.get(0)));\n    job.setNumMapTasks(numMaps);\n    LOG.info(\"Running \" + numMaps + \" maps.\");\n    job.setNumReduceTasks(0);\n    Date startTime=new Date();\n    LOG.info(\"Job started: \" + startTime);\n    JobClient.runJob(job);\n    Date endTime=new Date();\n    LOG.info(\"Job ended: \" + endTime);\n    LOG.info(\"The job took \" + (endTime.getTime() - startTime.getTime()) / 1000 + \" seconds.\");\n  }\n  return 0;\n}"
    },
    "Old_Method": "/** \n * This is the main routine for launching a distributed random write job. It runs 10 maps/node and each node writes 1 gig of data to a DFS file. The reduce doesn't do anything.\n * @throws IOException\n */\npublic int run(String[] args) throws Exception {\n  if (args.length == 0) {\n    return printUsage();\n  }\n  JobConf job=new JobConf(getConf());\n  job.setJarByClass(RandomTextWriter.class);\n  job.setJobName(\"random-text-writer\");\n  job.setOutputKeyClass(Text.class);\n  job.setOutputValueClass(Text.class);\n  job.setInputFormat(RandomWriter.RandomInputFormat.class);\n  job.setMapperClass(Map.class);\n  JobClient client=new JobClient(job);\n  ClusterStatus cluster=client.getClusterStatus();\n  int numMapsPerHost=job.getInt(\"test.randomtextwrite.maps_per_host\",10);\n  long numBytesToWritePerMap=job.getLong(\"test.randomtextwrite.bytes_per_map\",1 * 1024 * 1024* 1024);\n  if (numBytesToWritePerMap == 0) {\n    System.err.println(\"Cannot have test.randomtextwrite.bytes_per_map set to 0\");\n    return -2;\n  }\n  long totalBytesToWrite=job.getLong(\"test.randomtextwrite.total_bytes\",numMapsPerHost * numBytesToWritePerMap * cluster.getTaskTrackers());\n  int numMaps=(int)(totalBytesToWrite / numBytesToWritePerMap);\n  if (numMaps == 0 && totalBytesToWrite > 0) {\n    numMaps=1;\n    job.setLong(\"test.randomtextwrite.bytes_per_map\",totalBytesToWrite);\n  }\n  Class<? extends OutputFormat> outputFormatClass=SequenceFileOutputFormat.class;\n  List<String> otherArgs=new ArrayList<String>();\n  for (int i=0; i < args.length; ++i) {\n    try {\n      if (\"-outFormat\".equals(args[i])) {\n        outputFormatClass=Class.forName(args[++i]).asSubclass(OutputFormat.class);\n      }\n else {\n        otherArgs.add(args[i]);\n      }\n    }\n catch (    ArrayIndexOutOfBoundsException except) {\n      System.out.println(\"ERROR: Required parameter missing from \" + args[i - 1]);\n      return printUsage();\n    }\n  }\n  job.setOutputFormat(outputFormatClass);\n  FileOutputFormat.setOutputPath(job,new Path(otherArgs.get(0)));\n  job.setNumMapTasks(numMaps);\n  System.out.println(\"Running \" + numMaps + \" maps.\");\n  job.setNumReduceTasks(0);\n  Date startTime=new Date();\n  System.out.println(\"Job started: \" + startTime);\n  JobClient.runJob(job);\n  Date endTime=new Date();\n  System.out.println(\"Job ended: \" + endTime);\n  System.out.println(\"The job took \" + (endTime.getTime() - startTime.getTime()) / 1000 + \" seconds.\");\n  return 0;\n}\n",
    "File_Path": "hadoop-book/src/main/java/com/hadoopilluminated/examples/RandomTextWriter.java",
    "Start": 6049,
    "Stop": 9055,
    "Project_Name": "data/projects/hadoop-book",
    "Method_Name": "run"
}