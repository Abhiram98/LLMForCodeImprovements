{
    "Method_Improvements": {
        "Improvements": [
            {
                "Improvement": "Use logging instead of System.out.println and System.err.println",
                "Change_Diff": "- System.out.println\n- System.err.println\n+ Logger logger = LoggerFactory.getLogger(<Your Class Name>.class);\n+ logger.info\n+ logger.error",
                "Description": "System.out.println and System.err.println are not recommended for real-world applications. They are not thread-safe, and in multi-threaded applications, the messages from different threads may get mixed up. Also, you can't really control the output or format it. Using a logging framework provides benefits like different logging levels, flexible output (file, console, network, etc.), and control over format. It also helps to find/debug issues quickly.",
                "Start": 5,
                "End": 61
            },
            {
                "Improvement": "Avoid magic numbers",
                "Change_Diff": "- job.getInt(\"test.randomwriter.maps_per_host\",10);\n+ private static final int DEFAULT_MAPS_PER_HOST = 10;\n+ job.getInt(\"test.randomwriter.maps_per_host\", DEFAULT_MAPS_PER_HOST);",
                "Description": "Magic numbers are numbers that occur multiple time in the code without clear meaning. They should be replaced with named constants to improve code readability.",
                "Start": 37,
                "End": 51
            },
            {
                "Improvement": "Extract magic strings into constants",
                "Change_Diff": "- \"test.randomwriter.maps_per_host\"\n+ private static final String MAPS_PER_HOST_CONFIG = \"test.randomwriter.maps_per_host\";\n+ MAPS_PER_HOST_CONFIG",
                "Description": "Strings such as 'test.randomwriter.maps_per_host' are used multiple times in the code. These should be replaced with named constants to avoid errors due to typos and to make it easier to make changes if necessary.",
                "Start": 37,
                "End": 56
            }
        ],
        "Final code": "private static final Logger logger = LoggerFactory.getLogger(RandomWriter.class);\nprivate static final int DEFAULT_MAPS_PER_HOST = 10;\nprivate static final String MAPS_PER_HOST_CONFIG = \"test.randomwriter.maps_per_host\";\n\npublic int run(String[] args) throws Exception {\n  if (args.length == 0) {\n    logger.error(\"Usage: writer <out-dir>\");\n    ToolRunner.printGenericCommandUsage(System.out);\n    return -1;\n  }\n  Path outDir=new Path(args[0]);\n  JobConf job=new JobConf(getConf());\n  job.setJarByClass(RandomWriter.class);\n  job.setJobName(\"random-writer\");\n  FileOutputFormat.setOutputPath(job,outDir);\n  job.setOutputKeyClass(BytesWritable.class);\n  job.setOutputValueClass(BytesWritable.class);\n  job.setInputFormat(RandomInputFormat.class);\n  job.setMapperClass(Map.class);\n  job.setReducerClass(IdentityReducer.class);\n  job.setOutputFormat(SequenceFileOutputFormat.class);\n  JobClient client=new JobClient(job);\n  ClusterStatus cluster=client.getClusterStatus();\n  int numMapsPerHost=job.getInt(MAPS_PER_HOST_CONFIG, DEFAULT_MAPS_PER_HOST);\n  long numBytesToWritePerMap=job.getLong(\"test.randomwrite.bytes_per_map\",1 * 1024 * 1024* 1024);\n  if (numBytesToWritePerMap == 0) {\n    logger.error(\"Cannot have test.randomwrite.bytes_per_map set to 0\");\n    return -2;\n  }\n  long totalBytesToWrite=job.getLong(\"test.randomwrite.total_bytes\",numMapsPerHost * numBytesToWritePerMap * cluster.getTaskTrackers());\n  int numMaps=(int)(totalBytesToWrite / numBytesToWritePerMap);\n  if (numMaps == 0 && totalBytesToWrite > 0) {\n    numMaps=1;\n    job.setLong(\"test.randomwrite.bytes_per_map\",totalBytesToWrite);\n  }\n  job.setNumMapTasks(numMaps);\n  logger.info(\"Running \" + numMaps + \" maps.\");\n  job.setNumReduceTasks(0);\n  Date startTime=new Date();\n  logger.info(\"Job started: \" + startTime);\n  JobClient.runJob(job);\n  Date endTime=new Date();\n  logger.info(\"Job ended: \" + endTime);\n  logger.info(\"The job took \" + (endTime.getTime() - startTime.getTime()) / 1000 + \" seconds.\");\n  return 0;\n}"
    },
    "Old_Method": "/** \n * This is the main routine for launching a distributed random write job. It runs 10 maps/node and each node writes 1 gig of data to a DFS file. The reduce doesn't do anything.\n * @throws IOException\n */\npublic int run(String[] args) throws Exception {\n  if (args.length == 0) {\n    System.out.println(\"Usage: writer <out-dir>\");\n    ToolRunner.printGenericCommandUsage(System.out);\n    return -1;\n  }\n  Path outDir=new Path(args[0]);\n  JobConf job=new JobConf(getConf());\n  job.setJarByClass(RandomWriter.class);\n  job.setJobName(\"random-writer\");\n  FileOutputFormat.setOutputPath(job,outDir);\n  job.setOutputKeyClass(BytesWritable.class);\n  job.setOutputValueClass(BytesWritable.class);\n  job.setInputFormat(RandomInputFormat.class);\n  job.setMapperClass(Map.class);\n  job.setReducerClass(IdentityReducer.class);\n  job.setOutputFormat(SequenceFileOutputFormat.class);\n  JobClient client=new JobClient(job);\n  ClusterStatus cluster=client.getClusterStatus();\n  int numMapsPerHost=job.getInt(\"test.randomwriter.maps_per_host\",10);\n  long numBytesToWritePerMap=job.getLong(\"test.randomwrite.bytes_per_map\",1 * 1024 * 1024* 1024);\n  if (numBytesToWritePerMap == 0) {\n    System.err.println(\"Cannot have test.randomwrite.bytes_per_map set to 0\");\n    return -2;\n  }\n  long totalBytesToWrite=job.getLong(\"test.randomwrite.total_bytes\",numMapsPerHost * numBytesToWritePerMap * cluster.getTaskTrackers());\n  int numMaps=(int)(totalBytesToWrite / numBytesToWritePerMap);\n  if (numMaps == 0 && totalBytesToWrite > 0) {\n    numMaps=1;\n    job.setLong(\"test.randomwrite.bytes_per_map\",totalBytesToWrite);\n  }\n  job.setNumMapTasks(numMaps);\n  System.out.println(\"Running \" + numMaps + \" maps.\");\n  job.setNumReduceTasks(0);\n  Date startTime=new Date();\n  System.out.println(\"Job started: \" + startTime);\n  JobClient.runJob(job);\n  Date endTime=new Date();\n  System.out.println(\"Job ended: \" + endTime);\n  System.out.println(\"The job took \" + (endTime.getTime() - startTime.getTime()) / 1000 + \" seconds.\");\n  return 0;\n}\n",
    "File_Path": "hadoop-book/src/main/java/com/hadoopilluminated/examples/RandomWriter.java",
    "Start": 8237,
    "Stop": 10671,
    "Project_Name": "data/projects/hadoop-book",
    "Method_Name": "run"
}