{
    "Method_Improvements": {
        "Improvements": [
            {
                "Improvement": "Refactor the try-catch-finally blocks",
                "Change_Diff": "- final SequenceFile.Writer writer=SequenceFile.createWriter(fs,jobConf,file,LongWritable.class,LongWritable.class,CompressionType.NONE);\ntry {\n writer.append(offset,size);\n}\nfinally {\n writer.close();\n}\n+ try (final SequenceFile.Writer writer=SequenceFile.createWriter(fs,jobConf,file,LongWritable.class,LongWritable.class,CompressionType.NONE)) {\n writer.append(offset,size);\n}",
                "Description": "To avoid nested try-catch-finally blocks, it's recommended to use try-with-resources statement, which ensures that each resource is closed at the end of the statement.",
                "Start": 23,
                "End": 32
            },
            {
                "Improvement": "Remove System.out.println statements",
                "Change_Diff": "- System.out.println(\"Wrote input for Map #\" + i);\n+ LOG.info(\"Wrote input for Map #\" + i);",
                "Description": "Logging should be done through a logging framework like Log4j to provide better control over log levels and where the logs are outputted.",
                "Start": 33,
                "End": 33
            },
            {
                "Improvement": "Refactor code to use try-with-resources when reading a file",
                "Change_Diff": "- SequenceFile.Reader reader=new SequenceFile.Reader(fs,inFile,jobConf);\ntry {\n reader.next(numInside,numOutside);\n}\nfinally {\n reader.close();\n}\n+ try (SequenceFile.Reader reader=new SequenceFile.Reader(fs,inFile,jobConf)) {\n reader.next(numInside,numOutside);\n}",
                "Description": "To ensure that the SequenceFile.Reader is closed properly, even in the event of an exception, the try-with-resources statement should be used.",
                "Start": 41,
                "End": 47
            }
        ],
        "Final code": "public static BigDecimal estimate(int numMaps,long numPoints,JobConf jobConf) throws IOException {\n  jobConf.setJobName(PiEstimator.class.getSimpleName());\n  jobConf.setInputFormat(SequenceFileInputFormat.class);\n  jobConf.setOutputKeyClass(BooleanWritable.class);\n  jobConf.setOutputValueClass(LongWritable.class);\n  jobConf.setOutputFormat(SequenceFileOutputFormat.class);\n  jobConf.setMapperClass(PiMapper.class);\n  jobConf.setNumMapTasks(numMaps);\n  jobConf.setReducerClass(PiReducer.class);\n  jobConf.setNumReduceTasks(1);\n  jobConf.setSpeculativeExecution(false);\n  final Path inDir=new Path(TMP_DIR,\"in\");\n  final Path outDir=new Path(TMP_DIR,\"out\");\n  FileInputFormat.setInputPaths(jobConf,inDir);\n  FileOutputFormat.setOutputPath(jobConf,outDir);\n  final FileSystem fs=FileSystem.get(jobConf);\n  if (fs.exists(TMP_DIR)) {\n    throw new IOException(\"Tmp directory \" + fs.makeQualified(TMP_DIR) + \" already exists.  Please remove it first.\");\n  }\n  if (!fs.mkdirs(inDir)) {\n    throw new IOException(\"Cannot create input directory \" + inDir);\n  }\n  try {\n    for (int i=0; i < numMaps; ++i) {\n      final Path file=new Path(inDir,\"part\" + i);\n      final LongWritable offset=new LongWritable(i * numPoints);\n      final LongWritable size=new LongWritable(numPoints);\n      try (final SequenceFile.Writer writer=SequenceFile.createWriter(fs,jobConf,file,LongWritable.class,LongWritable.class,CompressionType.NONE)) {\n        writer.append(offset,size);\n      }\n      LOG.info(\"Wrote input for Map #\" + i);\n    }\n    LOG.info(\"Starting Job\");\n    final long startTime=System.currentTimeMillis();\n    JobClient.runJob(jobConf);\n    final double duration=(System.currentTimeMillis() - startTime) / 1000.0;\n    LOG.info(\"Job Finished in \" + duration + \" seconds\");\n    Path inFile=new Path(outDir,\"reduce-out\");\n    LongWritable numInside=new LongWritable();\n    LongWritable numOutside=new LongWritable();\n    try (SequenceFile.Reader reader=new SequenceFile.Reader(fs,inFile,jobConf)) {\n      reader.next(numInside,numOutside);\n    }\n    return BigDecimal.valueOf(4).setScale(20).multiply(BigDecimal.valueOf(numInside.get())).divide(BigDecimal.valueOf(numMaps)).divide(BigDecimal.valueOf(numPoints));\n  }\n  finally {\n    fs.delete(TMP_DIR,true);\n  }\n}"
    },
    "Old_Method": "/** \n * Run a map/reduce job for estimating Pi.\n * @return the estimated value of Pi\n */\npublic static BigDecimal estimate(int numMaps,long numPoints,JobConf jobConf) throws IOException {\n  jobConf.setJobName(PiEstimator.class.getSimpleName());\n  jobConf.setInputFormat(SequenceFileInputFormat.class);\n  jobConf.setOutputKeyClass(BooleanWritable.class);\n  jobConf.setOutputValueClass(LongWritable.class);\n  jobConf.setOutputFormat(SequenceFileOutputFormat.class);\n  jobConf.setMapperClass(PiMapper.class);\n  jobConf.setNumMapTasks(numMaps);\n  jobConf.setReducerClass(PiReducer.class);\n  jobConf.setNumReduceTasks(1);\n  jobConf.setSpeculativeExecution(false);\n  final Path inDir=new Path(TMP_DIR,\"in\");\n  final Path outDir=new Path(TMP_DIR,\"out\");\n  FileInputFormat.setInputPaths(jobConf,inDir);\n  FileOutputFormat.setOutputPath(jobConf,outDir);\n  final FileSystem fs=FileSystem.get(jobConf);\n  if (fs.exists(TMP_DIR)) {\n    throw new IOException(\"Tmp directory \" + fs.makeQualified(TMP_DIR) + \" already exists.  Please remove it first.\");\n  }\n  if (!fs.mkdirs(inDir)) {\n    throw new IOException(\"Cannot create input directory \" + inDir);\n  }\n  try {\n    for (int i=0; i < numMaps; ++i) {\n      final Path file=new Path(inDir,\"part\" + i);\n      final LongWritable offset=new LongWritable(i * numPoints);\n      final LongWritable size=new LongWritable(numPoints);\n      final SequenceFile.Writer writer=SequenceFile.createWriter(fs,jobConf,file,LongWritable.class,LongWritable.class,CompressionType.NONE);\n      try {\n        writer.append(offset,size);\n      }\n  finally {\n        writer.close();\n      }\n      System.out.println(\"Wrote input for Map #\" + i);\n    }\n    System.out.println(\"Starting Job\");\n    final long startTime=System.currentTimeMillis();\n    JobClient.runJob(jobConf);\n    final double duration=(System.currentTimeMillis() - startTime) / 1000.0;\n    System.out.println(\"Job Finished in \" + duration + \" seconds\");\n    Path inFile=new Path(outDir,\"reduce-out\");\n    LongWritable numInside=new LongWritable();\n    LongWritable numOutside=new LongWritable();\n    SequenceFile.Reader reader=new SequenceFile.Reader(fs,inFile,jobConf);\n    try {\n      reader.next(numInside,numOutside);\n    }\n  finally {\n      reader.close();\n    }\n    return BigDecimal.valueOf(4).setScale(20).multiply(BigDecimal.valueOf(numInside.get())).divide(BigDecimal.valueOf(numMaps)).divide(BigDecimal.valueOf(numPoints));\n  }\n  finally {\n    fs.delete(TMP_DIR,true);\n  }\n}\n",
    "File_Path": "hadoop-book/src/main/java/com/hadoopilluminated/examples/PiEstimator.java",
    "Start": 8217,
    "Stop": 11568,
    "Project_Name": "data/projects/hadoop-book",
    "Method_Name": "estimate"
}