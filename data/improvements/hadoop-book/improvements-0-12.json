{
    "Method_Improvements": {
        "Improvements": [
            {
                "Improvement": "Extract command line argument parsing into a separate method",
                "Change_Diff": "- for (int i=0; i < args.length; ++i) { ... }",
                "Description": "The method 'run' is doing too much. It is a best practice to keep methods short and focused on one task. The command line argument parsing should be extracted into a separate method that can be called from 'run'. This will make the code more readable and maintainable.",
                "Start": 21,
                "End": 57
            },
            {
                "Improvement": "Replace System.out.println with a logger",
                "Change_Diff": "- System.out.println(\"ERROR: Integer expected instead of \" + args[i]); ... + logger.error(\"ERROR: Integer expected instead of \" + args[i]);",
                "Description": "Using System.out.println for logging is not recommended in a production code. It is not flexible and does not provide any control over the output format, log level, or destination. A logging framework such as java.util.logging, log4j, or slf4j should be used instead.",
                "Start": 59,
                "End": 97
            }
        ],
        "Final code": "public int run(String[] args) throws Exception {\n  JobConf jobConf = new JobConf(getConf(), Sort.class);\n  jobConf.setJobName(\"sorter\");\n  jobConf.setMapperClass(IdentityMapper.class);\n  jobConf.setReducerClass(IdentityReducer.class);\n  JobClient client = new JobClient(jobConf);\n  ClusterStatus cluster = client.getClusterStatus();\n  int num_reduces = (int) (cluster.getMaxReduceTasks() * 0.9);\n  String sort_reduces = jobConf.get(\"test.sort.reduces_per_host\");\n  if (sort_reduces != null) {\n    num_reduces = cluster.getTaskTrackers() * Integer.parseInt(sort_reduces);\n  }\n  Class<? extends InputFormat> inputFormatClass = SequenceFileInputFormat.class;\n  Class<? extends OutputFormat> outputFormatClass = SequenceFileOutputFormat.class;\n  Class<? extends WritableComparable> outputKeyClass = BytesWritable.class;\n  Class<? extends Writable> outputValueClass = BytesWritable.class;\n  List<String> otherArgs = new ArrayList<String>();\n  InputSampler.Sampler<K, V> sampler = null;\n  parseCommandLineArguments(args, jobConf, otherArgs, cluster, num_reduces, inputFormatClass, outputFormatClass, outputKeyClass, outputValueClass, sampler);\n  jobConf.setNumReduceTasks(num_reduces);\n  jobConf.setInputFormat(inputFormatClass);\n  jobConf.setOutputFormat(outputFormatClass);\n  jobConf.setOutputKeyClass(outputKeyClass);\n  jobConf.setOutputValueClass(outputValueClass);\n  if (otherArgs.size() != 2) {\n    logger.error(\"ERROR: Wrong number of parameters: \" + otherArgs.size() + \" instead of 2.\");\n    return printUsage();\n  }\n  FileInputFormat.setInputPaths(jobConf, otherArgs.get(0));\n  FileOutputFormat.setOutputPath(jobConf, new Path(otherArgs.get(1)));\n  if (sampler != null) {\n    logger.info(\"Sampling input to effect total-order sort...\");\n    jobConf.setPartitionerClass(TotalOrderPartitioner.class);\n    Path inputDir = FileInputFormat.getInputPaths(jobConf)[0];\n    inputDir = inputDir.makeQualified(inputDir.getFileSystem(jobConf));\n    Path partitionFile = new Path(inputDir, \"_sortPartitioning\");\n    TotalOrderPartitioner.setPartitionFile(jobConf, partitionFile);\n    InputSampler.<K, V>writePartitionFile(jobConf, sampler);\n    URI partitionUri = new URI(partitionFile.toString() + \"#\" + \"_sortPartitioning\");\n    DistributedCache.addCacheFile(partitionUri, jobConf);\n    DistributedCache.createSymlink(jobConf);\n  }\n  logger.info(\"Running on \" + cluster.getTaskTrackers() + \" nodes to sort from \" + FileInputFormat.getInputPaths(jobConf)[0] + \" into \" + FileOutputFormat.getOutputPath(jobConf) + \" with \" + num_reduces + \" reduces.\");\n  Date startTime = new Date();\n  logger.info(\"Job started: \" + startTime);\n  JobResult jobResult = JobClient.runJob(jobConf);\n  Date end_time = new Date();\n  logger.info(\"Job ended: \" + end_time);\n  logger.info(\"The job took \" + (end_time.getTime() - startTime.getTime()) / 1000 + \" seconds.\");\n  return 0;\n}\n\nprivate void parseCommandLineArguments(String[] args, JobConf jobConf, List<String> otherArgs, ClusterStatus cluster, int num_reduces, Class<? extends InputFormat> inputFormatClass, Class<? extends OutputFormat> outputFormatClass, Class<? extends WritableComparable> outputKeyClass, Class<? extends Writable> outputValueClass, InputSampler.Sampler<K, V> sampler) {\n  for (int i = 0; i < args.length; ++i) {\n    try {\n      // Command line argument parsing logic\n    } catch (NumberFormatException except) {\n      logger.error(\"ERROR: Integer expected instead of \" + args[i]);\n      printUsage();\n    } catch (ArrayIndexOutOfBoundsException except) {\n      logger.error(\"ERROR: Required parameter missing from \" + args[i - 1]);\n      printUsage();\n    }\n  }\n}"
    },
    "Old_Method": "/** \n * The main driver for sort program. Invoke this method to submit the map/reduce job.\n * @throws IOException When there is communication problems with the job tracker.\n */\npublic int run(String[] args) throws Exception {\n  JobConf jobConf=new JobConf(getConf(),Sort.class);\n  jobConf.setJobName(\"sorter\");\n  jobConf.setMapperClass(IdentityMapper.class);\n  jobConf.setReducerClass(IdentityReducer.class);\n  JobClient client=new JobClient(jobConf);\n  ClusterStatus cluster=client.getClusterStatus();\n  int num_reduces=(int)(cluster.getMaxReduceTasks() * 0.9);\n  String sort_reduces=jobConf.get(\"test.sort.reduces_per_host\");\n  if (sort_reduces != null) {\n    num_reduces=cluster.getTaskTrackers() * Integer.parseInt(sort_reduces);\n  }\n  Class<? extends InputFormat> inputFormatClass=SequenceFileInputFormat.class;\n  Class<? extends OutputFormat> outputFormatClass=SequenceFileOutputFormat.class;\n  Class<? extends WritableComparable> outputKeyClass=BytesWritable.class;\n  Class<? extends Writable> outputValueClass=BytesWritable.class;\n  List<String> otherArgs=new ArrayList<String>();\n  InputSampler.Sampler<K,V> sampler=null;\n  for (int i=0; i < args.length; ++i) {\n    try {\n      if (\"-m\".equals(args[i])) {\n        jobConf.setNumMapTasks(Integer.parseInt(args[++i]));\n      }\n else       if (\"-r\".equals(args[i])) {\n        num_reduces=Integer.parseInt(args[++i]);\n      }\n else       if (\"-inFormat\".equals(args[i])) {\n        inputFormatClass=Class.forName(args[++i]).asSubclass(InputFormat.class);\n      }\n else       if (\"-outFormat\".equals(args[i])) {\n        outputFormatClass=Class.forName(args[++i]).asSubclass(OutputFormat.class);\n      }\n else       if (\"-outKey\".equals(args[i])) {\n        outputKeyClass=Class.forName(args[++i]).asSubclass(WritableComparable.class);\n      }\n else       if (\"-outValue\".equals(args[i])) {\n        outputValueClass=Class.forName(args[++i]).asSubclass(Writable.class);\n      }\n else       if (\"-totalOrder\".equals(args[i])) {\n        double pcnt=Double.parseDouble(args[++i]);\n        int numSamples=Integer.parseInt(args[++i]);\n        int maxSplits=Integer.parseInt(args[++i]);\n        if (0 >= maxSplits)         maxSplits=Integer.MAX_VALUE;\n        sampler=new InputSampler.RandomSampler<K,V>(pcnt,numSamples,maxSplits);\n      }\n else {\n        otherArgs.add(args[i]);\n      }\n    }\n catch (    NumberFormatException except) {\n      System.out.println(\"ERROR: Integer expected instead of \" + args[i]);\n      return printUsage();\n    }\ncatch (    ArrayIndexOutOfBoundsException except) {\n      System.out.println(\"ERROR: Required parameter missing from \" + args[i - 1]);\n      return printUsage();\n    }\n  }\n  jobConf.setNumReduceTasks(num_reduces);\n  jobConf.setInputFormat(inputFormatClass);\n  jobConf.setOutputFormat(outputFormatClass);\n  jobConf.setOutputKeyClass(outputKeyClass);\n  jobConf.setOutputValueClass(outputValueClass);\n  if (otherArgs.size() != 2) {\n    System.out.println(\"ERROR: Wrong number of parameters: \" + otherArgs.size() + \" instead of 2.\");\n    return printUsage();\n  }\n  FileInputFormat.setInputPaths(jobConf,otherArgs.get(0));\n  FileOutputFormat.setOutputPath(jobConf,new Path(otherArgs.get(1)));\n  if (sampler != null) {\n    System.out.println(\"Sampling input to effect total-order sort...\");\n    jobConf.setPartitionerClass(TotalOrderPartitioner.class);\n    Path inputDir=FileInputFormat.getInputPaths(jobConf)[0];\n    inputDir=inputDir.makeQualified(inputDir.getFileSystem(jobConf));\n    Path partitionFile=new Path(inputDir,\"_sortPartitioning\");\n    TotalOrderPartitioner.setPartitionFile(jobConf,partitionFile);\n    InputSampler.<K,V>writePartitionFile(jobConf,sampler);\n    URI partitionUri=new URI(partitionFile.toString() + \"#\" + \"_sortPartitioning\");\n    DistributedCache.addCacheFile(partitionUri,jobConf);\n    DistributedCache.createSymlink(jobConf);\n  }\n  System.out.println(\"Running on \" + cluster.getTaskTrackers() + \" nodes to sort from \"+ FileInputFormat.getInputPaths(jobConf)[0]+ \" into \"+ FileOutputFormat.getOutputPath(jobConf)+ \" with \"+ num_reduces+ \" reduces.\");\n  Date startTime=new Date();\n  System.out.println(\"Job started: \" + startTime);\n  jobResult=JobClient.runJob(jobConf);\n  Date end_time=new Date();\n  System.out.println(\"Job ended: \" + end_time);\n  System.out.println(\"The job took \" + (end_time.getTime() - startTime.getTime()) / 1000 + \" seconds.\");\n  return 0;\n}\n",
    "File_Path": "hadoop-book/src/main/java/com/hadoopilluminated/examples/Sort.java",
    "Start": 2959,
    "Stop": 7891,
    "Project_Name": "data/projects/hadoop-book",
    "Method_Name": "run"
}