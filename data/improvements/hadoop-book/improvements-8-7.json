{
    "Method_Improvements": {
        "Improvements": [
            {
                "Improvement": "Replace System.out.println with a logger",
                "Change_Diff": "- System.out.println(\"Generating \" + totalRows + \" using \"+ numSplits+ \" maps with step of \"+ rowsPerSplit);\n+ LOGGER.info(\"Generating \" + totalRows + \" using \"+ numSplits+ \" maps with step of \"+ rowsPerSplit);",
                "Description": "System.out.println is not very professional and it's not flexible. Using a logger, you can set levels of importance for messages, and you can also redirect these messages to several output targets.",
                "Start": 5,
                "End": 5
            },
            {
                "Improvement": "Use try-with-resources",
                "Change_Diff": "- InputSplit[] splits=new InputSplit[numSplits];\n+ try (InputSplit[] splits=new InputSplit[numSplits]) {",
                "Description": "Try-with-resources in Java automatically closes the resources used within the try block. This can be files, connections, streams etc. We can use it here to automatically close the InputSplit after it's no longer needed.",
                "Start": 6,
                "End": 12
            },
            {
                "Improvement": "Add null check",
                "Change_Diff": "- long totalRows=getNumberOfRows(job);\n+ long totalRows = job != null ? getNumberOfRows(job) : 0;",
                "Description": "Always add null checks to avoid NullPointerException.",
                "Start": 2,
                "End": 2
            }
        ],
        "Final code": "public InputSplit[] getSplits(JobConf job,int numSplits){\n  long totalRows = job != null ? getNumberOfRows(job) : 0;\n  long rowsPerSplit=totalRows / numSplits;\n  LOGGER.info(\"Generating \" + totalRows + \" using \"+ numSplits+ \" maps with step of \"+ rowsPerSplit);\n  try (InputSplit[] splits=new InputSplit[numSplits]) {\n      long currentRow=0;\n      for (int split=0; split < numSplits - 1; ++split) {\n        splits[split]=new RangeInputSplit(currentRow,rowsPerSplit);\n        currentRow+=rowsPerSplit;\n      }\n      splits[numSplits - 1]=new RangeInputSplit(currentRow,totalRows - currentRow);\n  }\n  return splits;\n}"
    },
    "Old_Method": "/** \n * Create the desired number of splits, dividing the number of rows between the mappers.\n */\npublic InputSplit[] getSplits(JobConf job,int numSplits){\n  long totalRows=getNumberOfRows(job);\n  long rowsPerSplit=totalRows / numSplits;\n  System.out.println(\"Generating \" + totalRows + \" using \"+ numSplits+ \" maps with step of \"+ rowsPerSplit);\n  InputSplit[] splits=new InputSplit[numSplits];\n  long currentRow=0;\n  for (int split=0; split < numSplits - 1; ++split) {\n    splits[split]=new RangeInputSplit(currentRow,rowsPerSplit);\n    currentRow+=rowsPerSplit;\n  }\n  splits[numSplits - 1]=new RangeInputSplit(currentRow,totalRows - currentRow);\n  return splits;\n}\n",
    "File_Path": "hadoop-book/src/main/java/com/hadoopilluminated/examples/terasort/TeraGen.java",
    "Start": 4921,
    "Stop": 5780,
    "Project_Name": "data/projects/hadoop-book",
    "Method_Name": "getSplits"
}