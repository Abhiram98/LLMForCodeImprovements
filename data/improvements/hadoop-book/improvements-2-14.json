{
    "Method_Improvements": {
        "Improvements": [
            {
                "Improvement": "Use try-with-resources instead of manual resource management",
                "Change_Diff": "- final SequenceFile.Writer writer=SequenceFile.createWriter(fs,jobConf,file,LongWritable.class,LongWritable.class,CompressionType.NONE);\n- try {\n-    writer.append(offset,size);\n-}\n-finally {\n-    writer.close();\n-}\n\n- SequenceFile.Reader reader=new SequenceFile.Reader(fs,inFile,jobConf);\n- try {\n-   reader.next(numInside,numOutside);\n-}\n-finally {\n-   reader.close();\n-}\n\n+ try (final SequenceFile.Writer writer=SequenceFile.createWriter(fs,jobConf,file,LongWritable.class,LongWritable.class,CompressionType.NONE)) {\n+    writer.append(offset,size);\n+ }\n\n+ try (SequenceFile.Reader reader=new SequenceFile.Reader(fs,inFile,jobConf)) {\n+    reader.next(numInside,numOutside);\n+ }",
                "Description": "Instead of manually opening and closing the 'writer' and 'reader' resources, use Java's try-with-resources feature. This ensures that the resources are always closed regardless of whether an exception is thrown. It also makes the code cleaner and easier to understand.",
                "Start": 30,
                "End": 38
            },
            {
                "Improvement": "Remove System.out.println statements",
                "Change_Diff": "- System.out.println(\"Wrote input for Map #\" + i);\n- System.out.println(\"Starting Job\");\n- System.out.println(\"Job Finished in \" + duration + \" seconds\");\n\n+ logger.info(\"Wrote input for Map #\" + i);\n+ logger.info(\"Starting Job\");\n+ logger.info(\"Job Finished in \" + duration + \" seconds\");",
                "Description": "System.out.println statements are not recommended for production code as they can negatively impact performance. Consider using a logger instead, which can provide more control over which log messages to output, and can also include useful metadata (such as timestamps) in the output.",
                "Start": 35,
                "End": 38
            }
        ],
        "Final code": "public static BigDecimal estimate(int numMaps,long numPoints,JobConf jobConf) throws IOException {\n  jobConf.setJobName(PiEstimator.class.getSimpleName());\n  jobConf.setInputFormat(SequenceFileInputFormat.class);\n  jobConf.setOutputKeyClass(BooleanWritable.class);\n  jobConf.setOutputValueClass(LongWritable.class);\n  jobConf.setOutputFormat(SequenceFileOutputFormat.class);\n  jobConf.setMapperClass(PiMapper.class);\n  jobConf.setNumMapTasks(numMaps);\n  jobConf.setReducerClass(PiReducer.class);\n  jobConf.setNumReduceTasks(1);\n  jobConf.setSpeculativeExecution(false);\n  final Path inDir=new Path(TMP_DIR,\"in\");\n  final Path outDir=new Path(TMP_DIR,\"out\");\n  FileInputFormat.setInputPaths(jobConf,inDir);\n  FileOutputFormat.setOutputPath(jobConf,outDir);\n  final FileSystem fs=FileSystem.get(jobConf);\n  if (fs.exists(TMP_DIR)) {\n    throw new IOException(\"Tmp directory \" + fs.makeQualified(TMP_DIR) + \" already exists.  Please remove it first.\");\n  }\n  if (!fs.mkdirs(inDir)) {\n    throw new IOException(\"Cannot create input directory \" + inDir);\n  }\n  try {\n    for (int i=0; i < numMaps; ++i) {\n      final Path file=new Path(inDir,\"part\" + i);\n      final LongWritable offset=new LongWritable(i * numPoints);\n      final LongWritable size=new LongWritable(numPoints);\n      try (final SequenceFile.Writer writer=SequenceFile.createWriter(fs,jobConf,file,LongWritable.class,LongWritable.class,CompressionType.NONE)) {\n        writer.append(offset,size);\n      }\n      logger.info(\"Wrote input for Map #\" + i);\n    }\n    logger.info(\"Starting Job\");\n    final long startTime=System.currentTimeMillis();\n    JobClient.runJob(jobConf);\n    final double duration=(System.currentTimeMillis() - startTime) / 1000.0;\n    logger.info(\"Job Finished in \" + duration + \" seconds\");\n    Path inFile=new Path(outDir,\"reduce-out\");\n    LongWritable numInside=new LongWritable();\n    LongWritable numOutside=new LongWritable();\n    try (SequenceFile.Reader reader=new SequenceFile.Reader(fs,inFile,jobConf)) {\n      reader.next(numInside,numOutside);\n    }\n    return BigDecimal.valueOf(4).setScale(20).multiply(BigDecimal.valueOf(numInside.get())).divide(BigDecimal.valueOf(numMaps)).divide(BigDecimal.valueOf(numPoints));\n  }\n  finally {\n    fs.delete(TMP_DIR,true);\n  }\n}"
    },
    "Old_Method": "/** \n * Run a map/reduce job for estimating Pi.\n * @return the estimated value of Pi\n */\npublic static BigDecimal estimate(int numMaps,long numPoints,JobConf jobConf) throws IOException {\n  jobConf.setJobName(PiEstimator.class.getSimpleName());\n  jobConf.setInputFormat(SequenceFileInputFormat.class);\n  jobConf.setOutputKeyClass(BooleanWritable.class);\n  jobConf.setOutputValueClass(LongWritable.class);\n  jobConf.setOutputFormat(SequenceFileOutputFormat.class);\n  jobConf.setMapperClass(PiMapper.class);\n  jobConf.setNumMapTasks(numMaps);\n  jobConf.setReducerClass(PiReducer.class);\n  jobConf.setNumReduceTasks(1);\n  jobConf.setSpeculativeExecution(false);\n  final Path inDir=new Path(TMP_DIR,\"in\");\n  final Path outDir=new Path(TMP_DIR,\"out\");\n  FileInputFormat.setInputPaths(jobConf,inDir);\n  FileOutputFormat.setOutputPath(jobConf,outDir);\n  final FileSystem fs=FileSystem.get(jobConf);\n  if (fs.exists(TMP_DIR)) {\n    throw new IOException(\"Tmp directory \" + fs.makeQualified(TMP_DIR) + \" already exists.  Please remove it first.\");\n  }\n  if (!fs.mkdirs(inDir)) {\n    throw new IOException(\"Cannot create input directory \" + inDir);\n  }\n  try {\n    for (int i=0; i < numMaps; ++i) {\n      final Path file=new Path(inDir,\"part\" + i);\n      final LongWritable offset=new LongWritable(i * numPoints);\n      final LongWritable size=new LongWritable(numPoints);\n      final SequenceFile.Writer writer=SequenceFile.createWriter(fs,jobConf,file,LongWritable.class,LongWritable.class,CompressionType.NONE);\n      try {\n        writer.append(offset,size);\n      }\n  finally {\n        writer.close();\n      }\n      System.out.println(\"Wrote input for Map #\" + i);\n    }\n    System.out.println(\"Starting Job\");\n    final long startTime=System.currentTimeMillis();\n    JobClient.runJob(jobConf);\n    final double duration=(System.currentTimeMillis() - startTime) / 1000.0;\n    System.out.println(\"Job Finished in \" + duration + \" seconds\");\n    Path inFile=new Path(outDir,\"reduce-out\");\n    LongWritable numInside=new LongWritable();\n    LongWritable numOutside=new LongWritable();\n    SequenceFile.Reader reader=new SequenceFile.Reader(fs,inFile,jobConf);\n    try {\n      reader.next(numInside,numOutside);\n    }\n  finally {\n      reader.close();\n    }\n    return BigDecimal.valueOf(4).setScale(20).multiply(BigDecimal.valueOf(numInside.get())).divide(BigDecimal.valueOf(numMaps)).divide(BigDecimal.valueOf(numPoints));\n  }\n  finally {\n    fs.delete(TMP_DIR,true);\n  }\n}\n",
    "File_Path": "hadoop-book/src/main/java/com/hadoopilluminated/examples/PiEstimator.java",
    "Start": 8217,
    "Stop": 11568,
    "Project_Name": "data/projects/hadoop-book",
    "Method_Name": "estimate"
}